{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfnQvGfvtH1w"
   },
   "source": [
    "# Getting started\n",
    "\n",
    "### CLEF 2025 - CheckThat! Lab  - Task 4 Scientific Web Discourse - Subtask 4b (Scientific Claim Source Retrieval)\n",
    "\n",
    "This notebook enables participants of subtask 4b to quickly get started. It includes the following:\n",
    "- Code to upload data, including:\n",
    "    - code to upload the collection set (CORD-19 academic papers' metadata)\n",
    "    - code to upload the query set (tweets with implicit references to CORD-19 papers)\n",
    "- Code to run a baseline retrieval model (BM25)\n",
    "- Code to implement a neural re-ranking approach\n",
    "- Code to evaluate both the baseline and neural models\n",
    "\n",
    "Participants are free to use this notebook and add their own models for the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8N7h9BhQI5m"
   },
   "source": [
    "## 1.a) Import the collection set\n",
    "The collection set contains metadata of CORD-19 academic papers.\n",
    "\n",
    "The preprocessed and filtered CORD-19 dataset is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "# 1) Download the collection set from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl' #MODIFY PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "SYBB3UYbMwTA"
   },
   "outputs": [],
   "source": [
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4v3lygNOQQSn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7718 entries, 162 to 1056448\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   cord_uid          7718 non-null   object        \n",
      " 1   source_x          7718 non-null   object        \n",
      " 2   title             7718 non-null   object        \n",
      " 3   doi               7677 non-null   object        \n",
      " 4   pmcid             4959 non-null   object        \n",
      " 5   pubmed_id         6233 non-null   object        \n",
      " 6   license           7718 non-null   object        \n",
      " 7   abstract          7718 non-null   object        \n",
      " 8   publish_time      7715 non-null   object        \n",
      " 9   authors           7674 non-null   object        \n",
      " 10  journal           6668 non-null   object        \n",
      " 11  mag_id            0 non-null      float64       \n",
      " 12  who_covidence_id  528 non-null    object        \n",
      " 13  arxiv_id          20 non-null     object        \n",
      " 14  label             7718 non-null   object        \n",
      " 15  time              7715 non-null   datetime64[ns]\n",
      " 16  timet             7718 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_collection.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "9veNFFGDZRx7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAUiDU0xXLBt"
   },
   "source": [
    "## 1.b) Import the query set\n",
    "\n",
    "The query set contains tweets with implicit references to academic papers from the collection set.\n",
    "\n",
    "The preprocessed query set is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "v8gwkZDSXPsd"
   },
   "outputs": [],
   "source": [
    "# 1) Download the query tweets from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b?ref_type=heads\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv' #MODIFY PATH\n",
    "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_dev.tsv' #MODIFY PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "szMEK3OkYLvX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5\n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul\n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8\n",
       "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1\n",
       "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "aslmTTJQyL2X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12853 entries, 0 to 12852\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   post_id     12853 non-null  int64 \n",
      " 1   tweet_text  12853 non-null  object\n",
      " 2   cord_uid    12853 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 301.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_query_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "B5X8FwLhLY3u"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2       73  I recall early on reading that researchers who...  sts48u9i\n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "t6gDlBZnLcdH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400 entries, 0 to 1399\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   post_id     1400 non-null   int64 \n",
      " 1   tweet_text  1400 non-null   object\n",
      " 2   cord_uid    1400 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_query_dev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP"
   },
   "source": [
    "# 2) Running the BM25 baseline\n",
    "The following code runs a BM25 baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "BHfJ7ItxO8u8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\jakob\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jakob\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rank_bm25) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:5]\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Fk4-BqEtTgUj"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve topk candidates using the BM25 model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_query_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_topk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_query_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweet_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_top_cord_uids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_query_dev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_topk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_query_dev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_top_cord_uids(x))\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve topk candidates using the BM25 model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_query_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_topk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_query_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mget_top_cord_uids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m df_query_dev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_topk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_query_dev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_top_cord_uids(x))\n",
      "Cell \u001b[1;32mIn[50], line 7\u001b[0m, in \u001b[0;36mget_top_cord_uids\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     tokenized_query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     doc_scores \u001b[38;5;241m=\u001b[39m \u001b[43mbm25\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mdoc_scores)[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      9\u001b[0m     bm25_topk \u001b[38;5;241m=\u001b[39m [cord_uids[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\rank_bm25.py:119\u001b[0m, in \u001b[0;36mBM25Okapi.get_scores\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m query:\n\u001b[0;32m    118\u001b[0m     q_freq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(doc\u001b[38;5;241m.\u001b[39mget(q) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_freqs])\n\u001b[1;32m--> 119\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midf\u001b[38;5;241m.\u001b[39mget(q) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m (q_freq \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\n\u001b[0;32m    120\u001b[0m                                        (q_freq \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1 \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m*\u001b[39m doc_len \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgdl)))\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Retrieve topk candidates using the BM25 model\n",
    "df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Initial Neural Re-ranking Implementation\n",
    "The following code implements a neural re-ranking approach to improve the BM25 baseline. We'll use a two-stage retrieval pipeline:\n",
    "\n",
    "1. First stage: Use BM25 to retrieve candidate documents (efficient lexical matching)\n",
    "2. Second stage: Re-rank those candidates with a neural model (better semantic understanding)\n",
    "\n",
    "For the neural model, we'll use the Sentence-BERT framework to encode queries and documents into dense vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for neural reranking\n",
    "!pip install -q sentence-transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced BM25 function that returns both IDs and scores for more candidates\n",
    "def get_top_cord_uids_extended(query, k=20):\n",
    "    text2bm25top = {}\n",
    "    if query in text2bm25top.keys():\n",
    "        return text2bm25top[query]\n",
    "    else:\n",
    "        tokenized_query = query.split(' ')\n",
    "        doc_scores = bm25.get_scores(tokenized_query)\n",
    "        indices = np.argsort(-doc_scores)[:k]\n",
    "        bm25_topk = [cord_uids[x] for x in indices]\n",
    "        bm25_scores = [doc_scores[x] for x in indices]\n",
    "\n",
    "        text2bm25top[query] = (bm25_topk, bm25_scores)\n",
    "        return bm25_topk, bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Re-ranker class\n",
    "class NeuralReranker:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.corpus_embeddings = None\n",
    "        self.corpus_texts = None\n",
    "        self.paper_ids = None\n",
    "        \n",
    "    def index_collection(self, df_collection):\n",
    "        # Create text representation for each document\n",
    "        self.corpus_texts = df_collection[:][['title', 'abstract']].apply(\n",
    "            lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "        self.paper_ids = df_collection[:]['cord_uid'].tolist()\n",
    "        \n",
    "        # Calculate embeddings for all documents (this may take some time)\n",
    "        print(\"Calculating document embeddings...\")\n",
    "        self.corpus_embeddings = self.model.encode(\n",
    "            self.corpus_texts, \n",
    "            convert_to_tensor=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        print(f\"Created embeddings for {len(self.corpus_texts)} documents\")\n",
    "    \n",
    "    def rerank_candidates(self, query, candidate_ids, candidate_scores=None, top_k=5):\n",
    "        \"\"\"Re-rank the candidate documents for a given query\"\"\"\n",
    "        # Get query embedding\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        \n",
    "        # Get embeddings for candidate documents\n",
    "        candidate_indices = [self.paper_ids.index(cid) for cid in candidate_ids]\n",
    "        candidate_embeddings = self.corpus_embeddings[candidate_indices]\n",
    "        \n",
    "        # Calculate cosine similarity between query and candidates\n",
    "        cos_scores = util.cos_sim(query_embedding, candidate_embeddings)[0]\n",
    "        \n",
    "        # If BM25 scores are provided, we can combine the scores\n",
    "        if candidate_scores is not None:\n",
    "            # Normalize BM25 scores\n",
    "            bm25_scores = torch.tensor(candidate_scores)\n",
    "            bm25_scores = bm25_scores / bm25_scores.max()\n",
    "            \n",
    "            # Combine scores (you can adjust the weights)\n",
    "            alpha = 0.3  # Weight for BM25 scores\n",
    "            combined_scores = alpha * bm25_scores + (1-alpha) * cos_scores\n",
    "        else:\n",
    "            combined_scores = cos_scores\n",
    "            \n",
    "        # Sort by score\n",
    "        top_results = torch.argsort(-combined_scores)[:top_k].tolist()\n",
    "        \n",
    "        # Return re-ranked document IDs\n",
    "        return [candidate_ids[i] for i in top_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 242/242 [10:59<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 7718 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the neural reranker\n",
    "reranker = NeuralReranker()\n",
    "\n",
    "# Index the collection (this may take some time depending on collection size)\n",
    "reranker.index_collection(df_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training and dev queries\n",
    "def process_queries(df_queries, top_k=5):\n",
    "    results = []\n",
    "    \n",
    "    for _, row in df_queries.iterrows():\n",
    "        query = row['tweet_text']\n",
    "        \n",
    "        # First-stage: Get BM25 candidates\n",
    "        bm25_candidates, bm25_scores = get_top_cord_uids_extended(query)\n",
    "        \n",
    "        # Second-stage: Neural re-ranking\n",
    "        reranked_candidates = reranker.rerank_candidates(\n",
    "            query, \n",
    "            bm25_candidates, \n",
    "            bm25_scores, \n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'post_id': row['post_id'],\n",
    "            'tweet_text': query,\n",
    "            'cord_uid': row['cord_uid'],\n",
    "            'bm25_topk': bm25_candidates[:5],  # For comparison\n",
    "            'neural_reranked': reranked_candidates\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training queries...\n",
      "Processing development queries...\n"
     ]
    }
   ],
   "source": [
    "# Process training and dev data\n",
    "print(\"Processing training queries...\")\n",
    "processed_train = process_queries(df_query_train)\n",
    "\n",
    "print(\"Processing development queries...\")\n",
    "processed_dev = process_queries(df_query_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 4) Evaluating the models\n",
    "The following code evaluates both the BM25 baseline and the neural re-ranking approach using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "BM25: {1: 0.5079747918773827, 5: 0.5508999196037242, 10: 0.5508999196037242}\n",
      "Neural re-ranking: {1: 0.5520112036100522, 5: 0.5959179439300811, 10: 0.5959179439300811}\n",
      "\n",
      "Development results:\n",
      "BM25: {1: 0.505, 5: 0.5520357142857142, 10: 0.5520357142857142}\n",
      "Neural re-ranking: {1: 0.5728571428571428, 5: 0.6121071428571428, 10: 0.6121071428571428}\n"
     ]
    }
   ],
   "source": [
    "# Compare BM25 baseline with neural re-ranking\n",
    "bm25_results_train = get_performance_mrr(processed_train, 'cord_uid', 'bm25_topk')\n",
    "neural_results_train = get_performance_mrr(processed_train, 'cord_uid', 'neural_reranked')\n",
    "\n",
    "bm25_results_dev = get_performance_mrr(processed_dev, 'cord_uid', 'bm25_topk')\n",
    "neural_results_dev = get_performance_mrr(processed_dev, 'cord_uid', 'neural_reranked')\n",
    "\n",
    "print(\"Training results:\")\n",
    "print(f\"BM25: {bm25_results_train}\")\n",
    "print(f\"Neural re-ranking: {neural_results_train}\")\n",
    "\n",
    "print(\"\\nDevelopment results:\")\n",
    "print(f\"BM25: {bm25_results_dev}\")\n",
    "print(f\"Neural re-ranking: {neural_results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Additional Exploration: \n",
    "Fine-tuning different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetuning 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2000 training examples. Skipped 0 queries with no matching papers.\n",
      "Fine-tuning the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 500/1250 [52:58<1:25:01,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1713, 'grad_norm': 1.3768905401229858, 'learning_rate': 1.4285714285714287e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1000/1250 [1:49:32<28:14,  6.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0985, 'grad_norm': 2.380155563354492, 'learning_rate': 4.761904761904762e-06, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [2:18:06<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8286.0565, 'train_samples_per_second': 2.414, 'train_steps_per_second': 0.151, 'train_loss': 0.12301238861083984, 'epoch': 10.0}\n",
      "Fine-tuned neural re-ranking results: {1: 0.5564285714285714, 5: 0.6033095238095239, 10: 0.6033095238095239}\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_model(df_train, model_name='all-MiniLM-L6-v2'):\n",
    "    from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Prepare training data\n",
    "    train_examples = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for _, row in df_train.iterrows():\n",
    "        query = row['tweet_text']\n",
    "        positive_paper_id = row['cord_uid']\n",
    "        \n",
    "        # Find matching papers in the collection and handle the case when no match is found\n",
    "        matching_papers = df_collection[df_collection['cord_uid'] == positive_paper_id]\n",
    "        if matching_papers.empty:\n",
    "            # Skip this example if no matching paper is found\n",
    "            skipped += 1\n",
    "            continue\n",
    "            \n",
    "        # Get the text of the positive paper - use .loc instead of .iloc\n",
    "        positive_index = matching_papers.index[0]\n",
    "        positive_text = f\"{df_collection.loc[positive_index, 'title']} {df_collection.loc[positive_index, 'abstract']}\"\n",
    "        \n",
    "        # Create a training example\n",
    "        train_examples.append(InputExample(\n",
    "            texts=[query, positive_text],\n",
    "            label=1.0  # Positive pair\n",
    "        ))\n",
    "        \n",
    "        # For each positive, sample some negatives\n",
    "        bm25_candidates, _ = get_top_cord_uids_extended(query, k=10)\n",
    "        neg_added = False\n",
    "        for neg_id in bm25_candidates:\n",
    "            if neg_id != positive_paper_id:\n",
    "                matching_neg_papers = df_collection[df_collection['cord_uid'] == neg_id]\n",
    "                if matching_neg_papers.empty:\n",
    "                    continue\n",
    "                    \n",
    "                neg_index = matching_neg_papers.index[0]\n",
    "                neg_text = f\"{df_collection.loc[neg_index, 'title']} {df_collection.loc[neg_index, 'abstract']}\"\n",
    "                \n",
    "                train_examples.append(InputExample(\n",
    "                    texts=[query, neg_text],\n",
    "                    label=0.0  # Negative pair\n",
    "                ))\n",
    "                neg_added = True\n",
    "                break  # Just add one negative for simplicity\n",
    "        \n",
    "        # If we couldn't find any valid negative, try a random paper\n",
    "        if not neg_added:\n",
    "            # Get a random paper that's not the positive one\n",
    "            random_indices = df_collection.sample(5).index\n",
    "            for idx in random_indices:\n",
    "                random_id = df_collection.loc[idx, 'cord_uid']\n",
    "                if random_id != positive_paper_id:\n",
    "                    random_text = f\"{df_collection.loc[idx, 'title']} {df_collection.loc[idx, 'abstract']}\"\n",
    "                    train_examples.append(InputExample(\n",
    "                        texts=[query, random_text],\n",
    "                        label=0.0  # Negative pair\n",
    "                    ))\n",
    "                    break\n",
    "    \n",
    "    print(f\"Created {len(train_examples)} training examples. Skipped {skipped} queries with no matching papers.\")\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "    \n",
    "    # Use the cosine similarity loss\n",
    "    train_loss = losses.CosineSimilarityLoss(model)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Fine-tuning the model...\")\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=10,  # You may need more epochs\n",
    "        warmup_steps=200,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "try:\n",
    "    # Only fine-tune on a subset of the data for faster execution\n",
    "    subset_size = min(1000, len(df_query_train))\n",
    "    fine_tuned_model = fine_tune_model(df_query_train.head(subset_size))\n",
    "    \n",
    "    # Update the reranker with the fine-tuned model\n",
    "    reranker.model = fine_tuned_model\n",
    "    \n",
    "    # Re-process with the fine-tuned model\n",
    "    processed_dev_finetuned = process_queries(df_query_dev)\n",
    "    \n",
    "    # Evaluate the fine-tuned model\n",
    "    neural_finetuned_results_dev = get_performance_mrr(processed_dev_finetuned, 'cord_uid', 'neural_reranked')\n",
    "    print(f\"Fine-tuned neural re-ranking results: {neural_finetuned_results_dev}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during fine-tuning: {e}\")\n",
    "    print(\"Proceeding with the pre-trained model only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attempted to finetune allenai/scibert_scivocab_uncased, failed due to matrix dimension mismatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n",
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2000 training examples. Skipped 0 queries with no matching papers.\n",
      "Fine-tuning the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 500/1250 [10:29:05<14:21:56, 68.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1739, 'grad_norm': 1.941263198852539, 'learning_rate': 1.4285714285714287e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1000/1250 [20:14:25<4:52:10, 70.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0415, 'grad_norm': 1.9587656259536743, 'learning_rate': 4.761904761904762e-06, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [25:28:09<00:00, 73.35s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 91689.2202, 'train_samples_per_second': 0.218, 'train_steps_per_second': 0.014, 'train_loss': 0.08956683120727539, 'epoch': 10.0}\n",
      "Error during fine-tuning: mat1 and mat2 shapes cannot be multiplied (1x768 and 384x20)\n",
      "Proceeding with the pre-trained model only.\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_model(df_train, model_name='allenai/scibert_scivocab_uncased'):\n",
    "    from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Prepare training data\n",
    "    train_examples = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for _, row in df_train.iterrows():\n",
    "        query = row['tweet_text']\n",
    "        positive_paper_id = row['cord_uid']\n",
    "        \n",
    "        # Find matching papers in the collection and handle the case when no match is found\n",
    "        matching_papers = df_collection[df_collection['cord_uid'] == positive_paper_id]\n",
    "        if matching_papers.empty:\n",
    "            # Skip this example if no matching paper is found\n",
    "            skipped += 1\n",
    "            continue\n",
    "            \n",
    "        # Get the text of the positive paper - use .loc instead of .iloc\n",
    "        positive_index = matching_papers.index[0]\n",
    "        positive_text = f\"{df_collection.loc[positive_index, 'title']} {df_collection.loc[positive_index, 'abstract']}\"\n",
    "        \n",
    "        # Create a training example\n",
    "        train_examples.append(InputExample(\n",
    "            texts=[query, positive_text],\n",
    "            label=1.0  # Positive pair\n",
    "        ))\n",
    "        \n",
    "        # For each positive, sample some negatives\n",
    "        bm25_candidates, _ = get_top_cord_uids_extended(query, k=10)\n",
    "        neg_added = False\n",
    "        for neg_id in bm25_candidates:\n",
    "            if neg_id != positive_paper_id:\n",
    "                matching_neg_papers = df_collection[df_collection['cord_uid'] == neg_id]\n",
    "                if matching_neg_papers.empty:\n",
    "                    continue\n",
    "                    \n",
    "                neg_index = matching_neg_papers.index[0]\n",
    "                neg_text = f\"{df_collection.loc[neg_index, 'title']} {df_collection.loc[neg_index, 'abstract']}\"\n",
    "                \n",
    "                train_examples.append(InputExample(\n",
    "                    texts=[query, neg_text],\n",
    "                    label=0.0  # Negative pair\n",
    "                ))\n",
    "                neg_added = True\n",
    "                break  # Just add one negative for simplicity\n",
    "        \n",
    "        # If we couldn't find any valid negative, try a random paper\n",
    "        if not neg_added:\n",
    "            # Get a random paper that's not the positive one\n",
    "            random_indices = df_collection.sample(5).index\n",
    "            for idx in random_indices:\n",
    "                random_id = df_collection.loc[idx, 'cord_uid']\n",
    "                if random_id != positive_paper_id:\n",
    "                    random_text = f\"{df_collection.loc[idx, 'title']} {df_collection.loc[idx, 'abstract']}\"\n",
    "                    train_examples.append(InputExample(\n",
    "                        texts=[query, random_text],\n",
    "                        label=0.0  # Negative pair\n",
    "                    ))\n",
    "                    break\n",
    "    \n",
    "    print(f\"Created {len(train_examples)} training examples. Skipped {skipped} queries with no matching papers.\")\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "    \n",
    "    # Use the cosine similarity loss\n",
    "    train_loss = losses.CosineSimilarityLoss(model)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Fine-tuning the model...\")\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=10,  # You may need more epochs\n",
    "        warmup_steps=200,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "try:\n",
    "    # Only fine-tune on a subset of the data for faster execution\n",
    "    subset_size = min(1000, len(df_query_train))\n",
    "    fine_tuned_model = fine_tune_model(df_query_train.head(subset_size))\n",
    "    \n",
    "    # Update the reranker with the fine-tuned model\n",
    "    reranker.model = fine_tuned_model\n",
    "    \n",
    "    # Re-process with the fine-tuned model\n",
    "    processed_dev_finetuned = process_queries(df_query_dev)\n",
    "    \n",
    "    # Evaluate the fine-tuned model\n",
    "    neural_finetuned_results_dev = get_performance_mrr(processed_dev_finetuned, 'cord_uid', 'neural_reranked')\n",
    "    print(f\"Fine-tuned neural re-ranking results: {neural_finetuned_results_dev}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during fine-tuning: {e}\")\n",
    "    print(\"Proceeding with the pre-trained model only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Evaluating different Models\n",
    "Evaluating different Models instead of attempting further finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) SciBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document embeddings with SciBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 242/242 [2:14:56<00:00, 33.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 7718 documents\n",
      "Processing development queries with SciBERT...\n",
      "\n",
      "Development results:\n",
      "SciBERT: {1: 0.48428571428571426, 5: 0.5314523809523809, 10: 0.5314523809523809}\n"
     ]
    }
   ],
   "source": [
    "# 1. SciBERT implementation\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Reset any previous models to avoid mixing\n",
    "if 'reranker' in locals():\n",
    "    del reranker\n",
    "\n",
    "# Neural Re-ranker using SciBERT\n",
    "class SciBERTReranker:\n",
    "    def __init__(self, model_name='allenai/scibert_scivocab_uncased'):\n",
    "        # Initialize the model using SentenceTransformer wrapper\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.corpus_embeddings = None\n",
    "        self.corpus_texts = None\n",
    "        self.paper_ids = None\n",
    "        \n",
    "    def index_collection(self, df_collection):\n",
    "        # Create text representation for each document\n",
    "        self.corpus_texts = df_collection[:][['title', 'abstract']].apply(\n",
    "            lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "        self.paper_ids = df_collection[:]['cord_uid'].tolist()\n",
    "        \n",
    "        # Calculate embeddings for all documents\n",
    "        print(\"Calculating document embeddings with SciBERT...\")\n",
    "        self.corpus_embeddings = self.model.encode(\n",
    "            self.corpus_texts, \n",
    "            convert_to_tensor=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        print(f\"Created embeddings for {len(self.corpus_texts)} documents\")\n",
    "    \n",
    "    def rerank_candidates(self, query, candidate_ids, candidate_scores=None, top_k=5):\n",
    "        \"\"\"Re-rank the candidate documents for a given query\"\"\"\n",
    "        # Get query embedding\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        \n",
    "        # Get embeddings for candidate documents\n",
    "        candidate_indices = [self.paper_ids.index(cid) for cid in candidate_ids]\n",
    "        candidate_embeddings = self.corpus_embeddings[candidate_indices]\n",
    "        \n",
    "        # Calculate cosine similarity between query and candidates\n",
    "        cos_scores = util.cos_sim(query_embedding, candidate_embeddings)[0]\n",
    "        \n",
    "        # If BM25 scores are provided, combine the scores\n",
    "        if candidate_scores is not None:\n",
    "            # Normalize BM25 scores\n",
    "            bm25_scores = torch.tensor(candidate_scores)\n",
    "            bm25_scores = bm25_scores / bm25_scores.max()\n",
    "            \n",
    "            # Combine scores (you can adjust the weights)\n",
    "            alpha = 0.3  # Weight for BM25 scores\n",
    "            combined_scores = alpha * bm25_scores + (1-alpha) * cos_scores\n",
    "        else:\n",
    "            combined_scores = cos_scores\n",
    "            \n",
    "        # Sort by score\n",
    "        top_results = torch.argsort(-combined_scores)[:top_k].tolist()\n",
    "        \n",
    "        # Return re-ranked document IDs\n",
    "        return [candidate_ids[i] for i in top_results]\n",
    "\n",
    "# Initialize SciBERT reranker\n",
    "scibert_reranker = SciBERTReranker()\n",
    "\n",
    "# Index the collection\n",
    "scibert_reranker.index_collection(df_collection)\n",
    "\n",
    "# Process the queries using SciBERT\n",
    "def process_queries_scibert(df_queries, top_k=5):\n",
    "    results = []\n",
    "    \n",
    "    for _, row in df_queries.iterrows():\n",
    "        query = row['tweet_text']\n",
    "        \n",
    "        # First-stage: Get BM25 candidates\n",
    "        bm25_candidates, bm25_scores = get_top_cord_uids_extended(query)\n",
    "        \n",
    "        # Second-stage: SciBERT re-ranking\n",
    "        reranked_candidates = scibert_reranker.rerank_candidates(\n",
    "            query, \n",
    "            bm25_candidates, \n",
    "            bm25_scores, \n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'post_id': row['post_id'],\n",
    "            'tweet_text': query,\n",
    "            'cord_uid': row['cord_uid'],\n",
    "            'bm25_topk': bm25_candidates[:5],  # For comparison\n",
    "            'scibert_reranked': reranked_candidates\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process dev data with SciBERT\n",
    "print(\"Processing development queries with SciBERT...\")\n",
    "processed_dev_scibert = process_queries_scibert(df_query_dev)\n",
    "\n",
    "# Evaluate SciBERT results\n",
    "scibert_results_dev = get_performance_mrr(processed_dev_scibert, 'cord_uid', 'scibert_reranked')\n",
    "print(\"\\nDevelopment results:\")\n",
    "print(f\"SciBERT: {scibert_results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) covid-twitter-bert-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name digitalepidemiologylab/covid-twitter-bert-v2. Creating a new one with mean pooling.\n",
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jakob\\.cache\\huggingface\\hub\\models--digitalepidemiologylab--covid-twitter-bert-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document embeddings with COVID-Twitter-BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 242/242 [7:53:01<00:00, 117.28s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 7718 documents\n",
      "Processing development queries with COVID-Twitter-BERT...\n",
      "\n",
      "Development results:\n",
      "COVID-Twitter-BERT: {1: 0.475, 5: 0.5396547619047619, 10: 0.5396547619047619}\n"
     ]
    }
   ],
   "source": [
    "# 2. COVID-Twitter-BERT implementation\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Reset any previous models to avoid mixing\n",
    "if 'scibert_reranker' in locals():\n",
    "    del scibert_reranker\n",
    "\n",
    "# Neural Re-ranker using COVID-Twitter-BERT\n",
    "class COVIDTwitterBERTReranker:\n",
    "    def __init__(self, model_name='digitalepidemiologylab/covid-twitter-bert-v2'):\n",
    "        # Initialize the model using SentenceTransformer wrapper\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.corpus_embeddings = None\n",
    "        self.corpus_texts = None\n",
    "        self.paper_ids = None\n",
    "        \n",
    "    def index_collection(self, df_collection):\n",
    "        # Create text representation for each document\n",
    "        self.corpus_texts = df_collection[:][['title', 'abstract']].apply(\n",
    "            lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "        self.paper_ids = df_collection[:]['cord_uid'].tolist()\n",
    "        \n",
    "        # Calculate embeddings for all documents\n",
    "        print(\"Calculating document embeddings with COVID-Twitter-BERT...\")\n",
    "        self.corpus_embeddings = self.model.encode(\n",
    "            self.corpus_texts, \n",
    "            convert_to_tensor=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        print(f\"Created embeddings for {len(self.corpus_texts)} documents\")\n",
    "    \n",
    "    def rerank_candidates(self, query, candidate_ids, candidate_scores=None, top_k=5):\n",
    "        \"\"\"Re-rank the candidate documents for a given query\"\"\"\n",
    "        # Get query embedding\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        \n",
    "        # Get embeddings for candidate documents\n",
    "        candidate_indices = [self.paper_ids.index(cid) for cid in candidate_ids]\n",
    "        candidate_embeddings = self.corpus_embeddings[candidate_indices]\n",
    "        \n",
    "        # Calculate cosine similarity between query and candidates\n",
    "        cos_scores = util.cos_sim(query_embedding, candidate_embeddings)[0]\n",
    "        \n",
    "        # If BM25 scores are provided, combine the scores\n",
    "        if candidate_scores is not None:\n",
    "            # Normalize BM25 scores\n",
    "            bm25_scores = torch.tensor(candidate_scores)\n",
    "            bm25_scores = bm25_scores / bm25_scores.max()\n",
    "            \n",
    "            # Combine scores (you can adjust the weights)\n",
    "            alpha = 0.3  # Weight for BM25 scores\n",
    "            combined_scores = alpha * bm25_scores + (1-alpha) * cos_scores\n",
    "        else:\n",
    "            combined_scores = cos_scores\n",
    "            \n",
    "        # Sort by score\n",
    "        top_results = torch.argsort(-combined_scores)[:top_k].tolist()\n",
    "        \n",
    "        # Return re-ranked document IDs\n",
    "        return [candidate_ids[i] for i in top_results]\n",
    "\n",
    "# Initialize COVID-Twitter-BERT reranker\n",
    "covid_twitter_bert_reranker = COVIDTwitterBERTReranker()\n",
    "\n",
    "# Index the collection\n",
    "covid_twitter_bert_reranker.index_collection(df_collection)\n",
    "\n",
    "# Process the queries using COVID-Twitter-BERT\n",
    "def process_queries_covid_twitter_bert(df_queries, top_k=5):\n",
    "    results = []\n",
    "    \n",
    "    for _, row in df_queries.iterrows():\n",
    "        query = row['tweet_text']\n",
    "        \n",
    "        # First-stage: Get BM25 candidates\n",
    "        bm25_candidates, bm25_scores = get_top_cord_uids_extended(query)\n",
    "        \n",
    "        # Second-stage: COVID-Twitter-BERT re-ranking\n",
    "        reranked_candidates = covid_twitter_bert_reranker.rerank_candidates(\n",
    "            query, \n",
    "            bm25_candidates, \n",
    "            bm25_scores, \n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'post_id': row['post_id'],\n",
    "            'tweet_text': query,\n",
    "            'cord_uid': row['cord_uid'],\n",
    "            'bm25_topk': bm25_candidates[:5],  # For comparison\n",
    "            'covid_twitter_bert_reranked': reranked_candidates\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process dev data with COVID-Twitter-BERT\n",
    "print(\"Processing development queries with COVID-Twitter-BERT...\")\n",
    "processed_dev_covid_twitter_bert = process_queries_covid_twitter_bert(df_query_dev)\n",
    "\n",
    "# Evaluate COVID-Twitter-BERT results\n",
    "covid_twitter_bert_results_dev = get_performance_mrr(processed_dev_covid_twitter_bert, 'cord_uid', 'covid_twitter_bert_reranked')\n",
    "print(\"\\nDevelopment results:\")\n",
    "print(f\"COVID-Twitter-BERT: {covid_twitter_bert_results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3) specter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name allenai/specter. Creating a new one with mean pooling.\n",
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jakob\\.cache\\huggingface\\hub\\models--allenai--specter. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\jakob\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document embeddings with SPECTER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 242/242 [2:15:00<00:00, 33.47s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 7718 documents\n",
      "Processing development queries with SPECTER...\n",
      "\n",
      "Development results:\n",
      "SPECTER: {1: 0.5364285714285715, 5: 0.5789404761904762, 10: 0.5789404761904762}\n"
     ]
    }
   ],
   "source": [
    "# 3. SPECTER implementation\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Reset any previous models to avoid mixing\n",
    "if 'covid_twitter_bert_reranker' in locals():\n",
    "    del covid_twitter_bert_reranker\n",
    "\n",
    "# Neural Re-ranker using SPECTER\n",
    "class SPECTERReranker:\n",
    "    def __init__(self, model_name='allenai/specter'):\n",
    "        # Initialize the model using SentenceTransformer wrapper\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.corpus_embeddings = None\n",
    "        self.corpus_texts = None\n",
    "        self.paper_ids = None\n",
    "        \n",
    "    def index_collection(self, df_collection):\n",
    "        # Create text representation for each document - SPECTER works best with title and abstract\n",
    "        self.corpus_texts = df_collection[:][['title', 'abstract']].apply(\n",
    "            lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "        self.paper_ids = df_collection[:]['cord_uid'].tolist()\n",
    "        \n",
    "        # Calculate embeddings for all documents\n",
    "        print(\"Calculating document embeddings with SPECTER...\")\n",
    "        self.corpus_embeddings = self.model.encode(\n",
    "            self.corpus_texts, \n",
    "            convert_to_tensor=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        print(f\"Created embeddings for {len(self.corpus_texts)} documents\")\n",
    "    \n",
    "    def rerank_candidates(self, query, candidate_ids, candidate_scores=None, top_k=5):\n",
    "        \"\"\"Re-rank the candidate documents for a given query\"\"\"\n",
    "        # Get query embedding\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        \n",
    "        # Get embeddings for candidate documents\n",
    "        candidate_indices = [self.paper_ids.index(cid) for cid in candidate_ids]\n",
    "        candidate_embeddings = self.corpus_embeddings[candidate_indices]\n",
    "        \n",
    "        # Calculate cosine similarity between query and candidates\n",
    "        cos_scores = util.cos_sim(query_embedding, candidate_embeddings)[0]\n",
    "        \n",
    "        # If BM25 scores are provided, combine the scores\n",
    "        if candidate_scores is not None:\n",
    "            # Normalize BM25 scores\n",
    "            bm25_scores = torch.tensor(candidate_scores)\n",
    "            bm25_scores = bm25_scores / bm25_scores.max()\n",
    "            \n",
    "            # Combine scores (you can adjust the weights)\n",
    "            alpha = 0.3  # Weight for BM25 scores\n",
    "            combined_scores = alpha * bm25_scores + (1-alpha) * cos_scores\n",
    "        else:\n",
    "            combined_scores = cos_scores\n",
    "            \n",
    "        # Sort by score\n",
    "        top_results = torch.argsort(-combined_scores)[:top_k].tolist()\n",
    "        \n",
    "        # Return re-ranked document IDs\n",
    "        return [candidate_ids[i] for i in top_results]\n",
    "\n",
    "# Initialize SPECTER reranker\n",
    "specter_reranker = SPECTERReranker()\n",
    "\n",
    "# Index the collection\n",
    "specter_reranker.index_collection(df_collection)\n",
    "\n",
    "# Process the queries using SPECTER\n",
    "def process_queries_specter(df_queries, top_k=5):\n",
    "    results = []\n",
    "    \n",
    "    for _, row in df_queries.iterrows():\n",
    "        query = row['tweet_text']\n",
    "        \n",
    "        # First-stage: Get BM25 candidates\n",
    "        bm25_candidates, bm25_scores = get_top_cord_uids_extended(query)\n",
    "        \n",
    "        # Second-stage: SPECTER re-ranking\n",
    "        reranked_candidates = specter_reranker.rerank_candidates(\n",
    "            query, \n",
    "            bm25_candidates, \n",
    "            bm25_scores, \n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'post_id': row['post_id'],\n",
    "            'tweet_text': query,\n",
    "            'cord_uid': row['cord_uid'],\n",
    "            'bm25_topk': bm25_candidates[:5],  # For comparison\n",
    "            'specter_reranked': reranked_candidates\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process dev data with SPECTER\n",
    "print(\"Processing development queries with SPECTER...\")\n",
    "processed_dev_specter = process_queries_specter(df_query_dev)\n",
    "\n",
    "# Evaluate SPECTER results\n",
    "specter_results_dev = get_performance_mrr(processed_dev_specter, 'cord_uid', 'specter_reranked')\n",
    "print(\"\\nDevelopment results:\")\n",
    "print(f\"SPECTER: {specter_results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BM25: {1: 0.505, 5: 0.5520357142857142, 10: 0.5520357142857142}\n",
      "all-MiniLM-L6-v2: {1: 0.5728571428571428, 5: 0.6121071428571428, 10: 0.6121071428571428}\n",
      "SPECTER: {1: 0.5364285714285715, 5: 0.5789404761904762, 10: 0.5789404761904762}\n",
      "COVID-Twitter-BERT: {1: 0.475, 5: 0.5396547619047619, 10: 0.5396547619047619}\n",
      "SciBERT: {1: 0.48428571428571426, 5: 0.5314523809523809, 10: 0.5314523809523809}\n",
      "Fine-tuned all-MiniLM-L6-v2: {1: 0.5564285714285714, 5: 0.6033095238095239, 10: 0.6033095238095239}\n"
     ]
    }
   ],
   "source": [
    "# BASE MODELS:\n",
    "print(f\"Baseline BM25: {bm25_results_dev}\")\n",
    "print(f\"all-MiniLM-L6-v2: {neural_results_dev}\")\n",
    "print(f\"SPECTER: {specter_results_dev}\")\n",
    "print(f\"COVID-Twitter-BERT: {covid_twitter_bert_results_dev}\")\n",
    "print(f\"SciBERT: {scibert_results_dev}\")\n",
    "\n",
    "# FINE-TUNED MODELS:\n",
    "print(f\"Fine-tuned all-MiniLM-L6-v2: {neural_finetuned_results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these Results, we will revisit the all-MiniLM-L6-v2 and optimize it inside our new notebook:  \n",
    "neural_re-ranking-submission.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
